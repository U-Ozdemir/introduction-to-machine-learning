# Introduction to Machine Learning
This directory contains a set of examples that will provide you with basic knowledge about Machine Learning. 

## Concepts Recap

**Model** - a mathematical representation of a real world process; a predictive model forecasts a future outcome based on past data.

**Algorithm** - a set of rules used to make a calculation or solve a problem.

**Training** - the process of creating a model from the training data. The data is fed into the training algorithm, which learns a representation for the problem, and produces a model. Also called “learning”.

**Regression** - a prediction method whose output is a real number, that is, a value that represents a quantity along a line. Example: predicting the temperature of an engine or the revenue of a company.

**Target** - in statistics, it is called the dependent variable; it is the output of the model or the variable you wish to predict.

**Classification** - a prediction method that assigns each data point to a predefined category, e.g., a type of operating system.

**Training set** - a dataset used to find potentially predictive relationships that will be used to create a model.

**Test set** - a dataset, separate from the training set but with the same structure, used to measure and benchmark the performance of various models.

**Feature** - also known as an independent variable or a predictor variable, a feature is an observable quantity, recorded and used by a prediction model. You can also engineer features by combining them or adding new information to them.

**Overfitting** - a situation in which a model that is too complex for the data has been trained to predict the target. This leads to an overly specialized model, which makes predictions that do not reflect the reality of the underlying relationship between the features and target.

## Get started
To get started clone the repository and create a new exercises branch. Start a Jupyter Notebook using:

```bash
> jupyter notebook
```

Go through the exercies in [01_Data_Cleaning](https://github.com/Dzvezdana/introduction-to-machine-learning/tree/master/01_Data_Cleaning) and [02_Models](https://github.com/Dzvezdana/introduction-to-machine-learning/tree/master/02_Models). Then go through this [Neural Network introduction tutorial](https://github.com/savarin/neural-networks). 

Extra work for the extra motivated. Finish these tutorials:

**Basic**:
* https://www.kaggle.com/learn/intro-to-machine-learning
* https://github.com/justmarkham/scikit-learn-videos
* https://www.kaggle.com/alexisbcook/categorical-variables
* https://www.kaggle.com/alexisbcook/missing-values
* https://www.kaggle.com/alexisbcook/pipelines


**Advanced**:
* Pick a challenge on [Kaggle](https://www.kaggle.com/). You can work in groups. Present the approach and the results at the end of the day.
* https://github.com/beginners-machine-learning-london/intro_to_unsupervised_ml_with_AWS_Sagemaker/blob/f70412e02fdff5b0ccb47c7fd51b2914b896062a/exercises/Intro%20to%20Unsupervised%20ML%20with%20AWS%20Sagemaker.ipynb

---

References:
* https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/
* https://github.com/qjcg/nb
